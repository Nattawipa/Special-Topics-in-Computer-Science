{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"W11.2 - Deep Learning with CIFAR10","provenance":[{"file_id":"1KvUMc4NqlF3cLIM6KehmkF_uOLeNFUFQ","timestamp":1603623068531}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"HPR_nNQ94KJ-"},"source":["# Prepare Environment"]},{"cell_type":"code","metadata":{"id":"m15_JQeGuaTX"},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","from IPython.display import display\n","\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","plt.rcParams[\"axes.grid\"] = False\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z--Q9_0x_0GP"},"source":["# TensorFlow and tf.keras\n","import tensorflow as tf\n","from tensorflow import keras\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_mQZIcK0Et2F"},"source":["**Note**: most of the code in the notebook is a simplified version of the tutorial example from Tensorflow ([here](https://www.tensorflow.org/tutorials/keras/classification))"]},{"cell_type":"markdown","metadata":{"id":"lXmN9g0ayjnx"},"source":["# Import the CIFAR10 dataset\n","\n","\n","\n","<table>\n","  <tr><td>\n","    <img src=\"https://cdn-images-1.medium.com/freeze/max/1000/1*LyV7_xga4jUHdx4_jHk1PQ.png\"\n","         alt=\"Fashion MNIST sprite\"  width=\"600\">\n","  </td></tr>\n","  <tr><td align=\"center\">\n","    <b>Figure 1.</b> <a href=\"https://www.cs.toronto.edu/~kriz/cifar.html\">CIFAR10 samples</a>, collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.<br/>&nbsp;\n","  </td></tr>\n","</table>\n","\n","Here, 50,000 images are used to train the network and 10,000 images to evaluate how accurately the network learned to classify images. Tensorflow provides CIFAR10 small images classification dataset that we can use as follows:\n","\n","The expected output:\n","\n","```\n","Training set: (50000, 32, 32, 3), (50000, 1)\n","Test set: (10000, 32, 32, 3), (10000, 1)\n","```"]},{"cell_type":"code","metadata":{"id":"U4yWlFbmhqCA"},"source":["from keras.datasets import cifar10\n","\n","(X_train, y_train), (X_test, y_test) = # YOUR CODE HERE\n","\n","print(f'Training set: {X_train.shape}, {y_train.shape}')\n","print(f'Test set: {X_test.shape}, {y_test.shape}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LluBFTgcuJg6"},"source":["Further split the training set into training (40,000) and validation (10,000) sets.\n","\n","The expected output:\n","```\n","Training set: (40000, 32, 32, 3), (40000, 1)\n","Validation set: (10000, 32, 32, 3), (10000, 1)\n","Test set: (10000, 32, 32, 3), (10000, 1)\n","```"]},{"cell_type":"code","metadata":{"id":"v11mMcG6TNrA"},"source":["# YOUR CODE HERE\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_valid, y_train, y_valid = # YOUR CODE HERE\n","\n","print(f'Training set: {X_train.shape}, {y_train.shape}')\n","print(f'Validation set: {X_valid.shape}, {y_valid.shape}')\n","print(f'Test set: {X_test.shape}, {y_test.shape}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EbQckWJhw2sm"},"source":["As the labels have an extra dimension (i.e., `(xxx, 1)`), we need to squeeze them to be `(xxx, )`. You may find the `np.squeeze()` function useful. The expected output should be\n","\n","```\n","Training set: (40000, 32, 32, 3), (40000,)\n","Validation set: (10000, 32, 32, 3), (10000,)\n","Test set: (10000, 32, 32, 3), (10000,)\n","```"]},{"cell_type":"code","metadata":{"id":"J-QhliNyw18M"},"source":["# YOUR CODE HERE\n","\n","print(f'Training set: {X_train.shape}, {y_train.shape}')\n","print(f'Validation set: {X_valid.shape}, {y_valid.shape}')\n","print(f'Test set: {X_test.shape}, {y_test.shape}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cj7twnRj1twi"},"source":["The images are 32x32x3 NumPy arrays, with pixel values ranging from 0 to 255. The *labels* are an array of integers, ranging from 0 to 9. These correspond to the following classes:\n","\n","<table>\n","  <tr>\n","    <th>Label</th>\n","    <th>Class</th>\n","  </tr>\n","  <tr>\n","    <td>0</td>\n","    <td>Airplane</td>\n","  </tr>\n","  <tr>\n","    <td>1</td>\n","    <td>Automobile</td>\n","  </tr>\n","    <tr>\n","    <td>2</td>\n","    <td>Bird</td>\n","  </tr>\n","    <tr>\n","    <td>3</td>\n","    <td>Cat</td>\n","  </tr>\n","    <tr>\n","    <td>4</td>\n","    <td>Deer</td>\n","  </tr>\n","    <tr>\n","    <td>5</td>\n","    <td>Dog</td>\n","  </tr>\n","    <tr>\n","    <td>6</td>\n","    <td>Frog</td>\n","  </tr>\n","    <tr>\n","    <td>7</td>\n","    <td>Horse</td>\n","  </tr>\n","    <tr>\n","    <td>8</td>\n","    <td>Ship</td>\n","  </tr>\n","    <tr>\n","    <td>9</td>\n","    <td>Truck</td>\n","  </tr>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"VRJChED62ZRw"},"source":["Each image is mapped to a single label. Since the *class names* are not included with the dataset, store them here to use later when plotting the images:"]},{"cell_type":"code","metadata":{"id":"ihj1dsAP1xud"},"source":["# class_names = # YOUR CODE HERE\n","class_names = [\n","    'airplane', 'automobile', 'bird', 'cat', 'deer', \n","    'dog', 'frog', 'horse', 'ship', 'truck']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dsyiuNmM2PwN"},"source":["Let's look at an example of the fashion MNIST."]},{"cell_type":"code","metadata":{"id":"mdSF79sb4lIw"},"source":["plt.figure()\n","plt.imshow(X_train[0])\n","plt.colorbar()\n","plt.grid(False)\n","plt.xlabel(class_names[y_train[0]])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qetkkccz5ISk"},"source":["# Data Preprocessing\n","\n","It is a common pratice to **normalize the range of independent variables or features of data**. This is mainly because many classifiers calculate the distance between two points by the Euclidean distance. If one of the features has a broad range of values, the distance will be governed by this particular feature. Therefore, the range of all features should be normalized **so that each feature contributes approximately proportionately to the final distance**.\n","\n","There are many other feature scaling techniques, which can be found in [here](https://en.wikipedia.org/wiki/Feature_scaling).\n","\n","In this exercise, we'll only scale the inputs to be in the range [0-1] rather than [0-255]."]},{"cell_type":"code","metadata":{"id":"1pnHXIU35HMU"},"source":["# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PjZ-uOK07wPM"},"source":["# Define a Model\n","\n","Please define a deep learning model that you would like to use for this problem here.\n","\n","**Hint**: The model need to first flatten the image from a three-dimensional array to a one-dimensional array before feeding to the `tf.keras.Dense` layer."]},{"cell_type":"code","metadata":{"id":"UEzRx5l576Bd"},"source":["from keras.models import Sequential\n","from keras.layers import *\n","\n","num_classes = # YOUR CODE HERE\n","\n","model = # YOUR CODE HERE\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zQCt2mvz8ROs"},"source":["# Train a Model\n","\n","In this section, we will first define several parameters that will be used during the training.\n","\n","*   `epochs`: the number of training epochs (one epoch means the model has seen the entire training samples one times).\n","*   `batch_size`: the number of examples per one training step.\n","*   `learning_rate`: a hyperparameter that defines the adjustment in the weights of our network with respect to the loss gradient.\n"]},{"cell_type":"code","metadata":{"id":"YjNa-rS28XqD"},"source":["epochs = # YOUR CODE HERE\n","batch_size = # YOUR CODE HERE\n","learning_rate = # YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UHeeybzy-taV"},"source":["## Loss Function\n","\n","Which loss function should we use for this CIFAR10?"]},{"cell_type":"code","metadata":{"id":"P8OGmVLq-RNm"},"source":["loss = # YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LvObkjaY-32N"},"source":["## Optimizer\n","\n","The optimizers that are commonly used to train deep learning models are Stochastic Gradient Descent (SGD), Adam, RMSProp, Adadelta, etc. The list of optimizers provided by TF-Keras can be found [here](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)."]},{"cell_type":"code","metadata":{"id":"VTq6EcE1-4fo"},"source":["optimizer = # YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VzG3YUL8_UdH"},"source":["## Compile the Model\n","\n","Next, we configures the model for training by calling `compile()` function."]},{"cell_type":"code","metadata":{"id":"CmCb0PgA_TJQ"},"source":["# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rkB6NPNuW0nE"},"source":["## Train a model\n","\n","We are now ready to train our model. Let's start feeding the data to train the model and it will learn to classify images.\n","\n","**Note**: The `fit()` function will return the training log, and we will keep it in `hist`.\n","\n","You can read more on the arguments for the `fit` function [here](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#fit)."]},{"cell_type":"code","metadata":{"id":"LJP7WcsO_bZA"},"source":["hist = # YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p6AQXxz0fguE"},"source":["Next we will plot the loss and the accuracy to see whether the model is subject to the overfitting or the underfitting problems."]},{"cell_type":"code","metadata":{"id":"3xGeVDPt2sJi"},"source":["fig, ax = plt.subplots(figsize=(8,6))\n","ax.plot(hist.history['loss'], label='train')\n","ax.plot(hist.history['val_loss'], label='valid')\n","ax.set_ylabel('Loss')\n","ax.set_xlabel('Epochs')\n","plt.legend()\n","plt.show()\n","\n","fig, ax = plt.subplots(figsize=(8,6))\n","ax.plot(hist.history['accuracy'], label='train')\n","ax.plot(hist.history['val_accuracy'], label='valid')\n","ax.set_ylabel('Accuracy')\n","ax.set_xlabel('Epochs')\n","plt.legend()\n","plt.show()\n","\n","plt.close('all')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Z5vkzZdQ6w0"},"source":["Let's see the model prediction in details. Here we will apply the trained model on the validation set.\n","\n","The expected output:\n","```\n","(10000, 10)\n","(10000,)\n","```"]},{"cell_type":"code","metadata":{"id":"shG_yjN8Qsdy"},"source":["# Predict the probability of each image\n","# y_hat_valid_probs = # YOUR CODE HERE\n","\n","# Select the class with the highest probability as the predicted class.\n","# y_hat_valid = # YOUR CODE HERE\n","\n","print(y_hat_valid_probs.shape)\n","print(y_hat_valid.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wZ66Xjd_SSnM"},"source":["To make it more human-friendly, we will visualize the input image and its corresponding prediction to see how our model performs."]},{"cell_type":"code","metadata":{"id":"6uLIb4CiDEn4"},"source":["def plot_image(i, probs, true_label, img):\n","    probs, true_label, img = probs, true_label[i], img[i]\n","    plt.grid(False)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.imshow(img, cmap=plt.cm.binary)\n","    predicted_label = np.argmax(probs)\n","    if predicted_label == true_label:\n","        color = 'blue'\n","    else:\n","        color = 'red'\n","    plt.xlabel(\n","        '{} {:2.0f}% ({})'.format(\n","            class_names[predicted_label],\n","            100*np.max(probs),\n","            class_names[true_label]),\n","        color=color)\n","    \n","def plot_prob_dist(i, probs, true_label):\n","    probs, true_label = probs, true_label[i]\n","    plt.grid(False)\n","    plt.xticks(range(10))\n","    plt.yticks([])\n","    thisplot = plt.bar(range(10), probs, color=\"#777777\")\n","    plt.ylim([0, 1])\n","    predicted_label = np.argmax(probs, axis=-1)\n","    thisplot[predicted_label].set_color('red')\n","    thisplot[true_label].set_color('blue')\n","\n","def plot_output(probs, images, labels):\n","    num_rows = 5\n","    num_cols = 3\n","    num_images = num_rows*num_cols\n","    plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n","    for i in range(num_images):\n","        plt.subplot(num_rows, 2*num_cols, 2*i+1)\n","        plot_image(i, probs[i], labels, images)\n","        plt.subplot(num_rows, 2*num_cols, 2*i+2)\n","        plot_prob_dist(i, probs[i], labels)\n","    plt.tight_layout()\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KrICW-6NRvxx"},"source":["<table>\n","  <tr>\n","    <th>Label</th>\n","    <th>Class</th>\n","  </tr>\n","  <tr>\n","    <td>0</td>\n","    <td>Airplane</td>\n","  </tr>\n","  <tr>\n","    <td>1</td>\n","    <td>Automobile</td>\n","  </tr>\n","    <tr>\n","    <td>2</td>\n","    <td>Bird</td>\n","  </tr>\n","    <tr>\n","    <td>3</td>\n","    <td>Cat</td>\n","  </tr>\n","    <tr>\n","    <td>4</td>\n","    <td>Deer</td>\n","  </tr>\n","    <tr>\n","    <td>5</td>\n","    <td>Dog</td>\n","  </tr>\n","    <tr>\n","    <td>6</td>\n","    <td>Frog</td>\n","  </tr>\n","    <tr>\n","    <td>7</td>\n","    <td>Horse</td>\n","  </tr>\n","    <tr>\n","    <td>8</td>\n","    <td>Ship</td>\n","  </tr>\n","    <tr>\n","    <td>9</td>\n","    <td>Truck</td>\n","  </tr>\n","</table>"]},{"cell_type":"code","metadata":{"id":"MUsLDGc-C4a8"},"source":["# Color correct predictions in blue and incorrect predictions in red.\n","plot_output(y_hat_valid_probs, X_valid, y_valid)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SP4PPu_eScBY"},"source":["from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","print('Validation Set')\n","print(confusion_matrix(y_true=y_valid, y_pred=y_hat_valid))\n","print(f'Accuracy: {accuracy_score(y_true=y_valid, y_pred=y_hat_valid):.2f}')\n","print(f'Macro F1-score: {f1_score(y_true=y_valid, y_pred=y_hat_valid, average=\"macro\"):.2f}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uukGYk3JXIgP"},"source":["# Evaluate Performance on Test Set\n","\n","Once you have finished the model training, you then evaluate the classification performance on the test set (i.e., the unseen dataset)."]},{"cell_type":"code","metadata":{"id":"TIlI5WiVjd4h"},"source":["# y_hat_test_probs = # YOUR CODE HERE\n","# y_hat_test = # YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wXZLfaurAblZ"},"source":["print('Test Set')\n","print(confusion_matrix(y_true=y_test, y_pred=y_hat_test))\n","print(f'Accuracy: {accuracy_score(y_true=y_test, y_pred=y_hat_test):.2f}')\n","print(f'Macro F1-score: {f1_score(y_true=y_test, y_pred=y_hat_test, average=\"macro\"):.2f}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_KRSdi9DkfOk"},"source":["# Error Analysis\n","\n","It's always a good idea to inspect the output and make sure everything looks fine. Here we'll look at some examples our model gets right, and some examples it gets wrong on the test sets.\n","\n","First, we determine which samples are correct or incorrect on the test set."]},{"cell_type":"code","metadata":{"id":"rtlKYzaVkq__"},"source":["correct_indices = # YOUR CODE HERE\n","incorrect_indices = # YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bKLdFq6YkrgF"},"source":["Then we plot the images with their corresponding classes. In the incorrect case, we also plot the ground truth classes for comparison."]},{"cell_type":"code","metadata":{"id":"5EVBgXTbUvjn"},"source":["# Correct\n","idx = np.random.choice(np.arange(len(correct_indices)), 15)\n","print('Correct')\n","plot_output(\n","    y_hat_test_probs[correct_indices[idx]],\n","    X_test[correct_indices[idx]],\n","    y_test[correct_indices[idx]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QUe20C0MVKKS"},"source":["# Incorrect\n","idx = np.random.choice(np.arange(len(incorrect_indices)), 15)\n","print('Incorrect')\n","plot_output(\n","    y_hat_test_probs[incorrect_indices[idx]],\n","    X_test[incorrect_indices[idx]],\n","    y_test[incorrect_indices[idx]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"81ekdVGwv1d5"},"source":[""],"execution_count":null,"outputs":[]}]}